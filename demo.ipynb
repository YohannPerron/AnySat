{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnySat Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AnySat is available through PyTorch Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/gastruc/anysat/zipball/main\" to /home/GAstruc/.cache/torch/hub/main.zip\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('gastruc/anysat', 'anysat', pretrained=True, force_reload=True, flash_attn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repo installation:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/gastruc/AnySat.git\n",
    "cd AnySat\n",
    "pip install -e AnySat\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hubconf import AnySat\n",
    "\n",
    "model = AnySat.from_pretrained('base', flash_attn=False) #Set flash_attn=True if you have flash-attn module installed (url flash attn)\n",
    "#device = \"cuda\" If you want to run on GPU default is cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments Reproduction\n",
    "\n",
    "All experiments are available in the [experiments](https://github.com/gastruc/AnySat/tree/main/experiments) folder.\n",
    "\n",
    "For the reproduction of AnySat envirnoment run:\n",
    "\n",
    "```bash\n",
    "# clone project\n",
    "git clone https://github.com/gastruc/anysat\n",
    "cd anysat\n",
    "\n",
    "# [OPTIONAL] create conda environment\n",
    "conda create -n anysat python=3.9\n",
    "conda activate anysat\n",
    "\n",
    "# install requirements\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Create data folder where you can put your datasets\n",
    "mkdir data\n",
    "# Create logs folder\n",
    "mkdir logs\n",
    "```\n",
    "\n",
    "And Then run the experiment you want:\n",
    "\n",
    "```bash\n",
    "# Run AnySat pretraining on GeoPlex\n",
    "python src/train.py exp=GeoPlex_AnySAT\n",
    "\n",
    "# Run AnySat finetuning on BraDD-S1TS\n",
    "python src/train.py exp=BraDD_AnySAT_FT\n",
    "\n",
    "# Run AnySat linear probing on BraDD-S1TS\n",
    "python src/train.py exp=BraDD_AnySAT_LP\n",
    "```\n",
    "\n",
    "You can modify through hydra all parameters you want. For example to train a Small version of AnySat on GeoPlex datasets, run:\n",
    "\n",
    "```bash\n",
    "python src/train.py exp=GeoPlex_AnySAT model=Any_Small_multi\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on AnySat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Template of data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna use an example from TreeSatAI-TS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import des données réelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get features from an observation of a batch of observations, you need to provide to the model a dictionnary where keys are from the list: \n",
    "| Dataset       | Description                       | Tensor Size                                          | Channels                                  | Resolution |\n",
    "|---------------|-----------------------------------|-----------------------------------------|-------------------------------------------|------------|\n",
    "| aerial        | Single date tensor |Bx4xHxW                                              | RGB, NiR                                  | 0.2m       |\n",
    "| aerial-flair  | Single date tensor |Bx5xHxW                                              | RGB, NiR, Elevation                       | 0.2m       |\n",
    "| spot          | Single date tensor |Bx3xHxW                                              | RGB                                       | 1m         |\n",
    "| naip          | Single date tensor |Bx4xHxW                                               | RGB                                       | 1.25m      |\n",
    "| s2            | Time series tensor |BxTx10xHxW                                          | B2, B3, B4, B5, B6, B7, B8, B8a, B11, B12 | 10m        |\n",
    "| s1-asc        | Time series tensor |BxTx2xHxW                                             | VV, VH                                     | 10m        |\n",
    "| s1            | Time series tensor |BxTx3xHxW                                            | VV, VH, Ratio                             | 10m        |\n",
    "| alos          | Time series tensor |BxTx3xHxW                                            | HH, HV, Ratio                             | 30m        |\n",
    "| l7            | Time series tensor |BxTx6xHxW                                            | B1, B2, B3, B4, B5, B7                    | 30m        |\n",
    "| l8            | Time series tensor |BxTx11xHxW                                           | B8, B1, B2, B3, B4, B5, B6, B7, B9, B10, B11 | 10m        |\n",
    "| modis         | Time series tensor |BxTx7xHxW                                            | B1, B2, B3, B4, B5, B6, B7                | 250m       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"aerial\": torch.randn(2, 4, 300, 300), #2 batch size, 4 channels, 300x300 pixels\n",
    "    \"s2\": torch.randn(2, 4, 10, 6, 6), #2 batch size, 4 dates, 10 channels, 6x6 pixels\n",
    "    \"s2_dates\": torch.randint(0, 367, (2, 4)),\n",
    "    \"s1\": torch.randn(2, 4, 3, 6, 6), #2 batch size, 4 dates, 10 channels, 6x6 pixels\n",
    "    \"s1_dates\": torch.randint(0, 367, (2, 4)),\n",
    "}\n",
    "## A changer par les données réelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series keys require a \"{key}_dates\" (for example \"s2_dates\") tensor of size BxT that value an integer that represent the day of the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide on:\n",
    "- **Patch size** (in m, must be a multiple of 10): adjust according to the scale of your tiles and GPU memory. In general, avoid having more than 1024 patches per tile.\n",
    "- **Output type**: Choose between:\n",
    "  - `'tile'`: Single vector per tile\n",
    "  - `'patch'`: A vector per patch\n",
    "  - `'dense'`: A vector per sub-patch. Doubles the size to the vectors\n",
    "  - `'all'`: A vector per patch with class token at first position\n",
    " \n",
    "The sub patches are `1x1` pixels for time series and `10x10` pixels for VHR images. If using `output='dense'`, specify the `output_modality`.\n",
    "Scale should divide the spatial cover of all modalities and be a multiple of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the type of output you want:\n",
    "- 'tile': to get the tile features\n",
    "- 'patch': to get the patch features\n",
    "- 'dense': to get the dense map at subpatch level\n",
    "    - If dense is selected, you can specify the modality you want to keep with modality_keep parameter, default is the first modality in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "features = model(data, patch_size=10, output='tile') \n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "features = model(data, patch_size=10, output='patch') \n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "features = model(data, patch_size=20, output='patch') \n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "features = model(data, patch_size=60, output='patch') \n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 30, 30, 1536])\n"
     ]
    }
   ],
   "source": [
    "features = model(data, patch_size=20, output='dense', output_modality=\"aerial\") \n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 6, 1536])\n"
     ]
    }
   ],
   "source": [
    "features = model(data, patch_size=20, output='dense', output_modality=\"s2\") \n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
